[![Review Assignment Due Date](https://classroom.github.com/assets/deadline-readme-button-22041afd0340ce965d47ae6ef1cefeee28c7c493a6346c4f15d667ab976d596c.svg)](https://classroom.github.com/a/gSldEXG6)
# Welcome to ○팀

## 1️⃣ 팀원 소개

| **이름** | **전공** | **관심사** |
| --- | --- | --- |
| **유환희** | 인공지능전공 |빅데이터, 인공지능, 헬스 |
| **얄공** | 인공지능전공 |게임하기, 기타치기 |
| **한윤성** | 인공지능전공 |운동, 노래듣기, 영화보기기  |
| **조유섭** | 인공지능전공 |운동, 스타트업, 인공지능|
| **박민영** | 인공지능전공 |웹툰보기, 영화보기,  노래부르기 |

유레카프로젝트 프로젝트 팀 생성을 축하합니다.
유레카프로젝트 프로젝트 팀의 제목과 팀원의 이름 및 관심사를 변경하세요.

### 팀 슬로건

Code the future.

### 팀 소개

인공지능 5팀입니다.

***

## 2️⃣ 공통된 관심사 : 여행, 백엔드, 인공지능

***

## 3️⃣ 한학기 동안의 활동 내역 

# 첫 번째 활동

## 1 (1965년, 서기 2000년대 생활의 이모저모)

**얄공**  
- **현재 실현된 기술:** 달나라로 수학여행 가는 것만 빼고는 다 현실이 되었다.  
- **느낀점:** 예전에는 꿈이었지만 지금은 현실이 되었다. 매일 쓰는 기술이 된 것이 신기하고 사람의 상상이 결국 미래를 만든다고 느꼈다.

**유환희**  
- **현재 실현된 기술:** 태양열 기술 전기자동차 소형 전화기(휴대전화) 로봇 청소기 부엌에서 사용하는 소형 TV 등.  
- **느낀점:** 1965년에 예측한 것인데 거의 대부분이 적중해서 놀랐다. 사람들의 꿈과 희망이 이루어지는 것을 보여준 영상이라 큰 동기부여가 되었다.

**박민영**  
- 1965년은 한국 전쟁 이후 복구도 제대로 안 된 시기라 사회 기반 시설이 무너져 있었다. 그런데 그런 시대에 35년 후의 미래를 현실적으로 예측했다는 점이 대단하다.  
- 스마트폰은 물론 화상통화와 인터넷까지 예측했고 로봇 청소기와 스마트 부엌도 모두 현실이 되었다.  
- 움직이는 도로는 무빙워크로 볼 수 있고 학생들은 인강 사이트를 활용하며 공부한다.  
- 태양열 발전 주택도 많고 전기차와 자율주행차도 도로에서 볼 수 있다.  
- 유일하게 아직 상용화되지 못한 것은 원격진료인데 기술적으로는 가능하지만 사회적 논의가 부족해 실제 활용은 안 되고 있다.  
- 당시 열악한 상황에서도 신문 스크랩 등을 통해 흐름을 연구한 결과 이렇게 정확하게 예측할 수 있었다는 점이 신기하고 대단하다.

**조유섭**  
- 대부분의 그림 속 기술은 실현된 것 같고 어려운 것은 달나라 수학여행과 원격진료다.  
- 달나라는 비용 문제가 크고 중력 문제도 있다. 원격진료는 이미 일부 국가에서는 시행 중이라 곧 상용화될 것 같다.  
- 과거 예측이 대부분 맞았던 것처럼 지금 말도 안 된다고 생각하는 기술도 50년 안에는 충분히 현실화될 수 있다고 생각한다.

---

## 2 (과거 사람들이 생각한 미래를 영상 3개 보고 쓴 것)

**얄공**  
- **현재 실현된 기술:** AR/스마트 글래스 스마트홈/IoT 제스처 인터페이스 디지털 협업 도구 등.  
- **느낀점:** 90년대의 미래 상상이 지금 현실로 구현된 것이 놀랍다. 기술 발전 속도가 빠르고 앞으로의 상상도 현실이 될 가능성이 크다는 점이 흥미롭다.

**유환희**  
- **현재 실현된 기술:** 터치 및 제스처 기반 기기 실시간 번역 클라우드 협업 태블릿 중심 학습 스마트홈 AR/MR 기술 강화유리 스마트 윈도우 대형 디스플레이 헬스케어 디지털화.  
- **느낀점:** 기술 발전 속도가 예상보다 빠르다. 불과 10여 년 만에 영상 속 기술 대부분이 현실이 되었다. 하지만 모든 장면이 현실이 된 것은 아니며 투명 디스플레이 집 같은 부분은 아직 멀다.  
- 그래도 연구가 진행 중이라 충분히 가능성이 있다. 또한 기술 발전이 개인정보 보호나 인간관계 변화 같은 문제도 가져오기 때문에 단순히 편리함만 볼 게 아니라 비판적인 시각도 필요하다고 느꼈다.

**박민영**  
- 미래 영상 속 스마트 미러와 제스처 기반 생활 모습이 인상적이었다. 아이들이 국적을 넘어 스마트 미러로 교감하는 장면은 학습에도 큰 도움이 될 것 같았다. 공항에서 기기로 길을 찾는 모습도 편리해 보였다.  
- 90년대 상상속 영상상 기술들은 대부분 현실이 되었고 스마트폰 결제나 OTT 플랫폼 등은 지금 일상이다.  
- 이렇게 빠른 변화 속도를 보면 앞으로의 미래는 더 빠르게 발전할 것이라고 생각한다.

**조유섭**  
- 영상 속 기술들은 비슷하게 상용화되고 있지만 모든 것을 하나로 통합하는 것은 어렵다.  
- 로봇이나 컴퓨터는 더 발전했지만 유리 기반 태블릿 같은 건 비용과 상용화 문제, 보안 문제 때문에 아직 힘들다.  
- 하나의 기기에 의존하다가 고장이나 분실이 생기면 불편할 수 있다는 점도 생각하게 된다.  
- 그래서 일부 기술은 구현되더라도 모든 것을 대체하기는 어렵다고 본다.

---

# 두 번째 활동

MIT Sixth Sense 연구팀이 만들고자 했던 것  

**Why?**  
- 현실과 디지털 세계를 자연스럽게 연결해 일상 속에서 정보를 직관적으로 활용하기 위해

**What?**  
- 카메라, 프로젝터, 센서를 결합한 휴대형 웨어러블 인터페이스  
- 손가락 제스처와 사물 인식을 통해 정보를 불러오고 조작  
- 책상, 벽, 손바닥 등 모든 표면을 스크린처럼 활용

**How?**  
- **하드웨어:** 프로젝터(정보 투사), 카메라(제스처·사물 인식), 스마트폰/소형 컴퓨터(데이터 처리), 손가락 마커(인식 보조)  
- **소프트웨어:** 제스처 인식 알고리즘으로 입력 해석 → 프로젝터로 현실에 정보 재투사  
- **철학:** 누구나 확장할 수 있도록 저비용·오픈소스로 개발

**As-Is vs To-Be**  
- 키보드 → 허공/표면 가상 키패드  
- 마우스 → 손 제스처로 이동·클릭  
- 모니터 → 주변 표면 어디든 디스플레이

**발전된 모습**  
- 제스처 인식: 초기에는 손가락 마커 + 단순 카메라 → 지금은 마커 없는 제스처 인식, 딥러닝·깊이 센서 활용  
- 출력 방식: 초기에는 프로젝터로 표면에 투사 → 지금은 AR/VR, 촉각 피드백, 웨어러블 센서 등 다양화  
- 응용 환경: 초기에는 실험실·데모 수준 → 지금은 구조, 소방, 헬스케어 등 실제 현장 적용  
- 사용자 참여: 초기에는 연구자 주도 → 지금은 사용자 참여·피드백 기반 공동 개발  
- 제품화: 초기에는 프로토타입 수준 → 지금은 일부 상용 제품, 기술 이전, 산업 적용 진행

---

# 세 번째 활동

**유환희**  
## 1. 도로 위 AR표시, 실시간 교통/미세먼지/에너지 흐름이 건물 표면에 데이터로 떠있는 3D 디지털 도시.  
## 2. 드론을 이용하여 교통혼잡에 영향을 받지 않고 빠르게 응급처치를 할 수 있는 플라잉 앰뷸런스.  
## 3. 손 대신 생각으로 커서를 움직여 문서 편집과 같은 작업을 할 수 있는 뇌-컴퓨터 인터페이스 업무  
## 4. 라이트필드 디스플레이가 책상 위에 3D앱들을 띄워 손가락의 미세한 움직임으로 창을 잡아당겨 이용할 수 있는 센서리스 제스처 디스플레이
## 5. 드로잉 프롬포트: “가로형 이소메트릭 도시 파노라마. 전경 왼쪽엔 눈에 기억칩을 이식한 커플이 TV 드론으로 5분 전 대화를 재생하며 말다툼, 오른쪽 보도엔 ‘나’가 뇌 속 신경칩으로 날씨 정보를 바로 확인. 중앙 도로와 건물 표면에는 실시간 교통·미세먼지·에너지 흐름 AR 데이터가 떠 있고, 오른쪽 건물 2층 단면에서는 라이트필드 디스플레이 위 3D 앱들을 손가락 미세 제스처로 정렬, 옆자리 사람은 BCI로 커서를 생각으로 조작. 상공에는 eVTOL 플라잉 앰뷸런스가 버티포트에 착륙하며 보조 드론이 응급 키트를 전송. 먼 하늘 왼쪽엔 날씨 제어 타워가 구름을 배열하고, 오른쪽엔 궤도 환승 링과 소형 셔틀이 점선 항로로 오간다. 보도에는 블록체인 행정 키오스크가 시민 노드로 작동. 따뜻한 오렌지/목재와 차가운 민트/네온 HUD의 대비, 손글씨 주석이 곳곳에 배치된 이정문식 유머·교육 톤.”	
## <img width="1024" height="1024" alt="Gemini_Generated_Image_wza4cuwza4cuwza4" src="https://github.com/user-attachments/assets/4707d55d-c4fa-434a-b903-d715040a5b20" />

**조유섭**  
## 1. 세상에 모든 거래와 행정이 블록체인 기반 → 2040~2050년의 미래에는 세상의 모든 거래와 행정이 블록체인 기반으로 이루어진다. 금융, 부동산, 세금, 병원 기록 등 모든 정보가 투명하게 기록되어 위·변조가 불가능하고, 사람들은 정부나 은행을 거치지 않아도 서로 직접 안전하게 거래할 수 있다. 이를 실현하려면 초고속·저비용의 블록체인 기술이 개발되어야 하며, 동시에 개인정보를 보호할 수 있는 강력한 암호화 기술과 국가 단위의 디지털 신원 인증 시스템이 필요하다. 또 각 기관 간의 데이터가 원활히 연결될 수 있도록 표준화가 이루어져야 하며, 법적·제도적 기반이 함께 마련되어야 한다.  
## 2. 뇌에 미세한 신경칩을 심어서 예를 들면 날씨 어때?라고 하면 바로 뇌에 정보가 뜨는 기술 → 사람의 뇌에 미세한 신경칩을 심어 생각만으로 정보를 확인하는 기술도 실현된다. 예를 들어 “날씨 어때?”라고 생각하면 눈앞에 바로 오늘의 기온과 강수량 정보가 떠오르는 식이다. 이를 위해서는 뇌의 신호를 정확하게 읽고, 그것을 언어 또는 이미지로 변환하는 인공지능 기술이 필수적이다. 또 신경칩의 안전성과 정확도를 높이고, 뇌와 외부 기기 간의 무선 연결을 안전하게 유지할 수 있는 통신 기술이 발전해야 한다. 하지만 생각이 노출될 위험이나 윤리적인 문제도 커지기 때문에, 개인의 프라이버시와 안전을 보장하는 법적 기준이 반드시 필요하다.  
## 3. 날씨를 인공지능이나 최첨단 기술을 통해 바꿀 수 있는 기술 → 인공지능과 첨단 기후 기술을 이용해 날씨를 바꾸는 시대가 온다. 폭우를 막거나 가뭄 지역에 비를 내리게 하는 것이 가능해지며, 인류는 기후 재해에 훨씬 유연하게 대응할 수 있게 된다. 이를 실현하려면 초정밀 기상 예측 시스템과 지구 전체의 기후 데이터를 실시간으로 분석할 수 있는 인공지능 기술이 필요하다. 또한 구름씨 살포처럼 환경을 해치지 않는 인공 기후 조절 방법이 개발되어야 하며, 이런 기술의 사용이 생태계나 기후 균형에 피해를 주지 않도록 국제적인 규제가 마련되어야 한다.  
## 4. 지금은 우주에 어떠한 행성을 갈려면 몇십년 몇백년 더 걸리는 이러한 거리를 자유롭게 여행할 수 있는 기술 → 현재 수십 년, 수백 년이 걸리는 우주 거리를 자유롭게 오갈 수 있는 기술도 가능해진다. 인류는 달이나 화성뿐 아니라 더 먼 행성까지 단기간에 이동하며 새로운 식민지나 탐사 기지를 세운다. 이를 위해서는 기존의 로켓보다 훨씬 강력한 핵융합 추진이나 레이저 추진 같은 차세대 엔진 기술이 필요하다. 우주 방사선을 차단하고 장기 비행 중 인체를 보호할 수 있는 신소재 개발도 필수적이다. 또한 인공지능이 자율적으로 항로를 계산하고 비행선을 관리할 수 있는 시스템이 함께 발전해야 한다. 다만 막대한 에너지 자원과 기술 비용, 인체 안전 문제 등은 여전히 해결해야 할 큰 과제이다.

**박민영**

---

<img width="1024" height="1024" alt="Gemini_Generated_Image_bae2q0bae2q0bae2 (1)" src="https://github.com/user-attachments/assets/f514bf50-e0a7-4bcb-b31b-6d433ac2f19d" />


## 1. 의식 복제 및 제어 기술 (Consciousness Replication and Control)

### 기술적 측면 설명

이 기술은 인간의 **의식(Consciousness)**, 즉 개인의 모든 지적, 감정적 정보를 **디지털 데이터**로 추출하여 컴퓨터 시스템에 업로드하는 것을 핵심으로 합니다. 그림 속 여성의 **'복제된 의식(Digital Clone)'**은 이 시스템에 존재하며, 물리적인 몸 없이도 집안일을 완벽하게 제어합니다.

* **정보 추출 및 디지털화:** **나노 센서**나 **뉴럴 링크 기술**을 이용해 뇌의 **시냅스 연결 지도(Connectome)**와 신경 활동 패턴을 초고해상도로 스캔합니다. 이 방대한 정보를 **양자 컴퓨팅** 기반의 저장소에 디지털 코드로 변환하여 저장합니다.
* **지능형 시뮬레이션:** 저장된 데이터를 기반으로 실제 뇌와 동일하게 작동하는 **지능형 소프트웨어**를 구동합니다. 이 소프트웨어는 스스로 사고하고 결정을 내리며, 그림처럼 홈 네트워크에 접속하여 **집안일 및 환경 제어**를 담당합니다. (예: 최적의 시간과 동선에 맞춰 로봇 청소, 냉난방 관리, 식재료 자동 주문 등)

### 현재 개발된 관련 기술 상황

* **기술적 한계:** 의식 전체를 복제하는 기술은 현재 **공상 과학** 수준에 머물러 있습니다. 인간 뇌의 복잡성을 완벽히 해독하고 디지털화하는 기술은 아직 개발되지 않았습니다.
* **관련 기술:** **뇌-컴퓨터 인터페이스(BCI)**는 뇌파를 외부 장치(컴퓨터 커서, 로봇 팔 등)로 전달하여 제어하는 기술로 이미 상용화되고 있습니다. 또한, **초지능 AI 비서**와 **스마트 홈 시스템**은 복제된 의식이 수행하는 '제어' 기능을 제한적으로 구현하고 있습니다.

---

## 2. 실시간 시청각 녹화 및 재생 기술 (Real-time Audiovisual Recording and Playback via Smart Contact Lens)

### 기술적 측면 설명

이 기술은 그림 속 여성이 착용하고 있는 **초소형 콘택트렌즈**를 통해 눈으로 보는 **시각 정보**와 주변 소리를 **청각 정보**로 실시간 기록하고, 이를 TV 화면에 즉시 스트리밍하여 재생하는 기술입니다.

* **콘택트렌즈 통합 센서:** 렌즈 내부에 **초미세 이미지 센서(마이크로 카메라)**와 **나노 마이크**가 집적되어 있습니다. 이 센서들은 사용자의 눈 움직임과 시야각을 따라 초고화질 영상과 고음질 사운드를 기록합니다.
* **무선 생체 에너지 구동:** 렌즈가 작동하는 데 필요한 전력은 사용자의 눈물이나 안구 운동 등 **생체 에너지**를 통해 얻거나, 외부 무선 충전 방식(RF 충전)을 통해 공급받습니다.
* **실시간 스트리밍 및 업무 활용:** 기록된 대용량 시청각 데이터는 렌즈에 내장된 **초소형 엣지 프로세서**에서 즉시 압축 및 처리됩니다. 이후 **초고속 무선 통신(예: 6G 또는 테라헤르츠 통신)**을 통해 다른 디스플레이(그림 속 TV)로 실시간 전송됩니다.
    * **재택근무 활용:** 그림에서 여성이 다른 디스플레이로 보고 있는 것처럼, 이 렌즈 기술은 **1인칭 시점**의 현장 상황(예: 동료의 시점으로 본 회의실이나 생산 라인)을 실시간으로 중계받아 원격으로 지시를 내리는 **'텔레프레즌스 재택근무'** 환경을 가능하게 합니다.

### 현재 개발된 관련 기술 상황

* **기술적 한계:** **완벽한 시청각 기록 및 스트리밍 기능**을 가진 상용화된 콘택트렌즈는 아직 없습니다. 초소형 배터리, 데이터 전송 발열 문제, 눈의 안전성 확보가 주요 과제입니다.
* **관련 기술:**
    * **스마트 콘택트렌즈 개발:** 삼성, 구글 등 다수의 기업 및 연구기관에서 **증강현실(AR)** 구현, 혈당 측정, 안압 측정 등을 위한 스마트 콘택트렌즈를 개발 중입니다. 이 초기 단계 렌즈들은 센서와 초소형 회로를 통합하는 데 성공하고 있습니다.
    * **1인칭 기록 장치:** **스마트 글래스**나 **액션캠**은 이미 1인칭 시점 기록 및 스트리밍 기능을 상용화했습니다. 이 기술의 소형화 및 렌즈 내 통합이 미래 목표입니다.

**한윤성**  
## - 도시 전체 센서 네트워크 연결 → 쓰레기 수거, 에너지 배분, 교통 흐름, 치안, 조명 자동 제어  
## - 자율주행 네트워크 차량 → “자동차 구독제” 형태 확산  
## - 인공지능+센서+GPS → 자율 비행 택배  
## - 뇌파·시각·감정 기반 인터페이스 → AR 안경, 피부 아래 센서 → 혈당·호르몬·스트레스 실시간 측정  
## - 조기 질병 예측 및 맞춤형 자동 투여기기 등장






<img src="https://raw.githubusercontent.com/사용자명/저장소명/브랜치명/경로/파일명.png" width="1024" height="1024" alt="설명">







    

- 기관/부서 인터뷰 ✔️  

- 현장 탐방 ✔️  

- 멘토링 ✔️  
  - 내 지도 교수 함게 만나기
  - 대학원 방문 및 선배 만나기

- 프로젝트 진행 ✔️  
  - 과거에 사람들이 상상한 미래
  - 그들이 만들어가는 세상
  - 우리가 상상한 미래
  - 우리가 그리는 미래 그리고 나

- 각오와 소감 나누기 ✔️  


<!-- 활동 사진 추가 예시 -->
<img src="https://pixnio.com/free-images/2017/08/14/2017-08-14-13-09-09-960x651.jpg?text=활동사진1" width="330" height="190"/>
<img src="https://pixnio.com/free-images/2017/08/14/2017-08-14-20-51-02-960x640.jpg?text=활동사진2" width="330" height="190"/>
<img src="https://pixnio.com/free-images/2017/08/15/2017-08-15-10-05-39-960x640.jpg?text=활동사진3" width="330" height="190"/>

***

## 4️⃣ 인상 깊은 활동

- 활동명 – 활동에 대한 간단한 설명과 배운 점을 작성  
- 예: 멘토링에서 실리콘밸리 현업 경험을 들을 수 있어 진로 방향 설정에 큰 도움이 되었다.  

***

## 5️⃣ 특별히 알아보고 싶은 것
- 예: 현장실습 제도
- 예: TOPCIT 정기평가
- 예: 졸업 후 진로(대학원/취업)

***

## 6️⃣ 활동을 마친 소감

🔗학번 이름  
> "소감 내용을 여기에 작성합니다."

🔗학번 이름  
> "소감 내용을 여기에 작성합니다."

🔗학번 이름  
> "소감 내용을 여기에 작성합니다."

🔗학번 이름  
> "소감 내용을 여기에 작성합니다."

🔗학번 이름  
> "소감 내용을 여기에 작성합니다."


## Markdown을 사용하여 내용꾸미기를 익히세요.

Markdown은 작문을 스타일링하기위한 가볍고 사용하기 쉬운 구문입니다. 여기에는 다음을위한 규칙이 포함됩니다.

```markdown
Syntax highlighted code block

# Header 1
## Header 2
### Header 3

- Bulleted
- List

1. Numbered
2. List

**Bold** and _Italic_ and `Code` text

[Link](url) and ![Image](src)
```

자세한 내용은 [GitHub Flavored Markdown](https://guides.github.com/features/mastering-markdown/).

### Support or Contact

readme 파일 생성에 추가적인 도움이 필요하면 [도움말](https://help.github.com/articles/about-readmes/) 이나 [contact support](https://github.com/contact) 을 이용하세요.

